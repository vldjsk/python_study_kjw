### 웹 크롤링 ###

#! 1. 웹 크롤링 (web crawling)
# : 웹 페이지를 체계적으로 탐색하여 추출하는 행위
# : 웹 크롤러 - 크롤링을 수행하는 프로그램

#! 2. 웹 크롤링 목적
# 2-1.검색 엔진 최적화(SEO)
# : 웹 크롤러는 검색엔진에서 웹페이지의 내용을 인덱싱(추출)하기위해 사용
# 2-2 데이터 수집 
# : 특정 웹 사이트에서 정보를 수집할 경우 사용
# 2-3 시장조사, 콘텐츠 모니터링

#! 3. 파이썬을 이용한 웹 크롤링
# : 외부 라이브러리의 지원
# : 확장성 - 다양한 데이터 처리 및 분석 도구와의 연동이 용이

#! 4. HTTP의 기본 이해
# HTTP(hypertext trasfer protocol)
# : 웹에서 데이터를 주고받는 규약

# 4-1. HTTP와 웹 크롤링의 관계
# : 웹 크롤링 시 웹 서버에게 정보를 요정하고 그응답을 받아오는 과정에서 HTTP를사용

# 4-2. HTTP 요청과 응답 
# 요청(request): 웹 브라우저(클로러)가 서버에게 정보나 서비스를 요청하는 메시지
# 응답(respdnse): 서버가 요청을 처리한후 반환하는 메시지

# 4-3. HTTP 메서드
# GET: 웹 페이지의 내용을 조회할때 사용 웹 크롤링에서 가장 기본적인 요청방식
# POST: 서버에 데이터를 보낼때 사용

# 4-4. HTTP 상테 코드(크롤링중 발생할수있는 상태)
# 200 OK: 성공적으로 응답 받았음(크롤링 대상 데이터를 가져오기 가능)
# 403 Forbidden: 접근 권한이 없음. (로봇 차단 정책 등으로 )
